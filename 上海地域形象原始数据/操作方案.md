# 思路规整

- 老师，我好好看了研究设计，我们想的是有问题的。
- 首先，第一页 2424 这个数据没有问题，但是从 2424 里抽取再编码的 895 不能再反向作用于研究 2424 这个样本量分属各个维度的过程中去，因为这 895 篇文本是从 2424 里筛选出的，换句话说，2424 里能挑选出有效数据的就是 895，比如说涉及城市形象里城市居民的一共344 条，这代表什么呢？这代表 2424 篇里涉及到城市居民的一共是 344 条，换句话说，如果要研究 2424 里涉及这一城市居民维度的，那么 344 就是总量，而不应该重新去寻找 2424 里有多少，因为 344 实际上可以视为总量 23422 中涉及城市居民这一维度的特征数量，但不能看成是 2424 的特征数量，而是总量。因为这 344 本身是从 2424 中人工筛选出来的，如果重新应用回 2424，那就是循环论证，是没有意义的，因为 2424 里涉及城市居民的一共就 344。如果非要当作特征，只能是作为标签去研究总量23422，然而这个标签量就太少了，因为344 只占 23422 的 1.46%，是不足以支撑研究有效性的。
- 其次，如果要分析第一页数据，即 2424 里城市形象的各个维度，那么其实已经得到结论了，也就是 895 里得出的各个数据，比如城市居民就是 344，同理，2424 里的其他维度有多少数量也已经得出了，等同于 895 里的各个具体值。当然一个文本可以有多个身份，这不冲突。
- 再次，理解这里面的难点在于，895 人工编码的数量是对 2424 的筛选，而不仅仅是简单的抽样，是去除无效性数据的总计。这 895 是 2424 的有效数据，属于数据清理的步骤，如果按照特征工程的原理而言，如前所述，895 对应的应该是 23422 整体，而非 2424 这个样本量。
- 厘清下思路：
- - 第一，如果研究样本为 2424，那么各个维度的数据量实际已经经过人工程序得出，换句话说，2424 的有效研究对象就是 895 这个整体样本，如果 从895 整体内再分割特征去应用于 2424 是无效的，是循环论证。
  - 第二，如果维持现有研究设计不变，即视 2424 为研究对象，那么研究对象理当顺延为 895。也可以这样理解：2424 里有不合格样本，实际上人工过程做了一个剔除脏数据（不合格数据）的过程，这个过程本该是计算机的工作，然而人工做了。
  - 第三，实际上，895 抽取的特征有双重性质，其一是 2424 的数据清洗过程；其二是 23422 的特征提取过程，但是 895 的数量对于 23422 而言又太小。
- 最后，分析对象应该是这 895 里的各个维度的数量，比如城市居民的样本数就是 344，这 344 也就是 2424 里的**有效数据**，依次类推，如果要分析城市居民的情感倾向，就应该对这 344 数据进行分析，得出的结论就是 2424（第一页）的结论，因为 2424-344 之外的数据，对于城市居民这个维度而言，就是**脏数据**。

## 最终结论：

**应该老师不是从一开始按照深度学习的要求来处理数据，所以无意中给这个筛选数据的过程赋予了双重含义。第一重含义是从 23422 到 2424 是个分层抽样的过程，标准是每十页的第一页，但是从 2424 到 895 的过程是人工编码，逐一进行评价，以确定其维度归属，这是剔除无效数据的过程，剩下的 895，按照维度（选择标准）而言，就是全部有效数据。第二重含义是 895 可以视为 23422 的特征，但是太小。**

以上是我的想法，一句话，从 2424到 895 的过程，不是一个提取 2424 数据量特征的过程，而是一个剔除无效数据的过程。

2020.2.29 01:34